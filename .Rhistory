??stop_words
tidytext::stop_words
library(openxlsx)
library(topicmodels)
library(ldatuning)
library(tokenizers)
library(tm)
library(tidyverse)
library(tidytext)
setwd("C:/Users/david/Documents/Website/darthur2.github.io/")
reviews_file <- "files/book_reviews.xlsx"
reviews <- read.xlsx(reviews_file)
reviews$Book[1]
reviews$Author[1]
substr(reviews$Reviews[1], 1, 500)
?tokenize_words
stopwords("en")
stop_words
stop_words$word
review_words <- tokenize_words(reviews$Reviews,
stopwords = stop_words,
strip_numeric = TRUE) %>%
sapply(., paste, collapse = " ")
review_words[1]
review_words <- tokenize_words(reviews$Reviews,
stopwords = stop_words$word,
strip_numeric = TRUE) %>%
sapply(., paste, collapse = " ")
review_words
review_words[1]
Encoding("’")
Encoding("'") <- "latin1"
x <- "'"
Encoding(x)
Encoding(x) <- "latin1"
x
Encoding(x)
x
Encoding(x) <- "latin1"
Encoding(x)
review_words[2]
x <- "’"
Encoding(x) <- "UTF-8"
x
test <- gsub("\u0092", "'", reviews$Reviews)
test[1]
test <- iconv(reviews$Reviews, from = "latin1", to = "UTF-8")
test[1]
test2 <- gsub("\u0092", "'", test)
test2[1]
test3 <- iconv(test2, from = "UTF-8", to = "ASCII")
test3
test2[1]
Encoding(test2)
test3 <- iconv(test2, from = "UTF-8", to = "latin1")
test3[1]
Encoding("â€œlessonsâ€\u009d")
x <- "\u0092"
Encoding(x)
iconv(x, from = "UTF-8", to = "latin1")
latin_comma <- iconv("\u0092", from = "UTF-8", to = "latin1")
reviews$Reviews <- gsub(latin_comma, "'", reviews$Reviews)
reviews$Reviews[1]
review_words <- tokenize_words(reviews$Reviews,
stopwords = stop_words$word,
strip_numeric = TRUE) %>%
sapply(., paste, collapse = " ")
review_words[1]
newbery_dtm <- review_words %>% VectorSource() %>% SimpleCorpus() %>%
DocumentTermMatrix(control = list(removeNumbers = TRUE,
stopwords = stop_words$word,
stemming = TRUE,
removePunctuation = TRUE,
tolower = TRUE))
colnames(as.matrix(newbery_dtm))
"read" %in% colnames(as.matrix(newbery_dtm))
?weightTfIdf
test <- tidy(reviews$Reviews)
test <- tidy(reviews$Reviews) %>% VectorSource() %>% SimpleCorpus()
?tidy
newbery_corpus <- review_words %>% VectorSource() %>% SimpleCorpus()
newbery_corpus
newbery_corpus$1
newbery_corpus$2
newbery_corpus <- review_words %>% VectorSource() %>% SimpleCorpus()
newbery_dtm <- newbery_corpus %>%
DocumentTermMatrix(control = list(removeNumbers = TRUE,
stopwords = stop_words$word,
stemming = TRUE,
removePunctuation = TRUE,
tolower = TRUE))
newbery_tdm <- newbery_corpus %>%
TermDocumentMatrix(control = list(removeNumbers = TRUE,
stopwords = stop_words$word,
stemming = TRUE,
removePunctuation = TRUE,
tolower = TRUE))
test <- weightTfIdf(newbery_tdm)
test2 <- weightTfIdf(newbery_dtm)
test2
as.matrix(test2)[1:10,1:10]
?DocumentTermMatrix
newbery_corpus <- review_words %>% VectorSource() %>% SimpleCorpus()
newbery_dtm <- newbery_corpus %>%
DocumentTermMatrix(control = list(removeNumbers = TRUE,
stopwords = stop_words$word,
stemming = TRUE,
removePunctuation = TRUE,
tolower = TRUE)) %>%
weightTfIdf()
test <- as.matrix(newbery_dtm)
test2 <- colSums(test)
test2[1:20]
qqnorm(test2)
summary(test2)
hist(test2)
test2["read"]
test2["tree"]
test2["newbery"]
test2["newb"]
test2["newber"]
"newb" %in% names(test2)
"new" %in% names(test2)
test2["new"]
test2[test2 > 0.1]
quantile(test2, 0.99)
quantile(test2, 0.01)
test2[test2 < 0.00278]
reviews_file <- "files/book_reviews.xlsx"
reviews <- read.xlsx(reviews_file)
reviews$Book[1]
reviews$Author[1]
substr(reviews$Reviews[1], 1, 500)
reviews_file <- "files/book_reviews.xlsx"
reviews <- read.xlsx(reviews_file)
library(openxlsx)
library(topicmodels)
library(ldatuning)
library(tokenizers)
library(tm)
library(tidyverse)
library(tidytext)
reviews_file <- "files/book_reviews.xlsx"
reviews <- read.xlsx(reviews_file)
reviews$Book[1]
reviews$Author[1]
